import os
import json
from dotenv import load_dotenv
import google.generativeai as genai
from typing import List, Dict

from search import fetch_search_results


def setup_genai():
    load_dotenv()
    api_key = os.getenv('GOOGLE_API_KEY') or os.getenv('GEMINI_API_KEY')
    model_name = os.getenv('MODEL_NAME', 'models/gemini-2.5-flash-lite-preview-09-2025')
    if not api_key:
        raise ValueError('GOOGLE_API_KEY (or GEMINI_API_KEY) not found in environment')
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)
    return model


def ask_llm_should_search(model, question: str) -> Dict:
    """å• LLM æ˜¯å¦éœ€è¦æœå°‹ï¼Œä¸¦è«‹å®ƒç”¨ JSON å›ç­”ï¼š{'need_search': bool, 'query': str}

    å¦‚æœ LLM å›å‚³é JSONï¼Œæœƒå˜—è©¦è§£æå¤±æ•—å¾Œä»¥ä¿å®ˆç­–ç•¥å›å‚³ need_search=Falseã€‚
    """
    system = (
        "ä½ æ˜¯ä¸€å€‹èƒ½å¤ åˆ¤æ–·æ˜¯å¦éœ€è¦ç¶²è·¯æœå°‹ä¾†å›ç­”å•é¡Œçš„åŠ©æ‰‹ã€‚"
        "è«‹åƒ…å›å‚³ JSONï¼Œæ ¼å¼ï¼š{\"need_search\": true|false, \"query\": \"...\"}ã€‚"
        "å¦‚æœä¸éœ€è¦æœå°‹ï¼Œè«‹å°‡ need_search è¨­ç‚º false ä¸¦æä¾›ç©ºå­—ä¸²çš„ queryã€‚"
    )

    prompt = f"å•é¡Œ: {question}\n\nè«‹ä¾ç…§ç³»çµ±æŒ‡ç¤ºå›è¦† JSONã€‚"
    try:
        response = model.generate_content(f"{system}\n\n{prompt}")
        text = getattr(response, 'text', '')
        # è§£æå¯èƒ½å‡ºç¾çš„ JSON
        try:
            parsed = json.loads(text.strip())
            return parsed
        except Exception:
            # å˜—è©¦åœ¨å›æ‡‰ä¸­æŠ½å‡º JSON ç‰©ä»¶
            start = text.find('{')
            end = text.rfind('}')
            if start != -1 and end != -1 and end > start:
                try:
                    parsed = json.loads(text[start:end+1])
                    return parsed
                except Exception:
                    return {'need_search': False, 'query': ''}
            return {'need_search': False, 'query': ''}
    except Exception as e:
        print(f"LLM æ±ºç­–å‘¼å«å¤±æ•—: {e}")
        return {'need_search': False, 'query': ''}


def ask_llm_summarize(model, question: str, search_items: List[Dict]) -> str:
    """æŠŠæœå°‹çµæœé¤µçµ¦ LLMï¼Œä¸¦è¦æ±‚å®ƒç”¢ç”Ÿç°¡æ½”æº–ç¢ºçš„æ‘˜è¦ç­”æ¡ˆã€‚"""
    # æŠŠæœå°‹çµæœæ‹¼æˆä¸€å€‹ä¹¾æ·¨çš„æ–‡å­—å¡Šï¼ˆåªä¿ç•™ title, snippet, linkï¼‰
    snippet_lines = []
    for i, it in enumerate(search_items[:8]):
        snippet_lines.append(f"[{i+1}] {it.get('title','')}: {it.get('snippet','')} ({it.get('link','')})")

    context = "\n".join(snippet_lines)

    system = (
        "ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç ”ç©¶åŠ©ç†ï¼Œè² è²¬åœ¨æä¾›çš„ç¶²è·¯æœå°‹çµæœä¸­æ‰¾å‡ºäº‹å¯¦æ€§è³‡è¨Šä¸¦å›è¦†åŸå§‹å•é¡Œã€‚"
        "è«‹ä¾æ“šæä¾›çš„æœå°‹çµæœå›ç­”ï¼Œä¸¦åœ¨ç­”æ¡ˆæœ€å¾Œæ¨™è¨»ä½¿ç”¨äº†å¹¾å€‹æœå°‹ä¾†æºã€‚"
    )

    prompt = (
        f"åŸå§‹å•é¡Œï¼š{question}\n\n"
        "ä»¥ä¸‹æ˜¯æª¢ç´¢åˆ°çš„æœå°‹çµæœï¼ˆåŸå§‹ï¼‰ï¼›è«‹åŸºæ–¼é€™äº›çµæœç”¢ç”Ÿä¸€å€‹ç°¡æ½”ã€äº‹å¯¦å°å‘çš„ç­”æ¡ˆã€‚"
        f"\n\n{context}\n\nå›ç­”ï¼š"
    )

    try:
        response = model.generate_content(f"{system}\n\n{prompt}")
        return getattr(response, 'text', '')
    except Exception as e:
        print(f"LLM ç”Ÿæˆæ‘˜è¦å¤±æ•—: {e}")
        return "ç„¡æ³•ç”± LLM ç”¢ç”Ÿæ‘˜è¦ï¼ˆç™¼ç”ŸéŒ¯èª¤ï¼‰ã€‚"


def run_agent():
    # åˆå§‹åŒ–
    try:
        model = setup_genai()
    except Exception as e:
        print(f"Agent åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
        return

    load_dotenv()
    cse_key = os.getenv('GOOGLE_CSE_API_KEY') or os.getenv('GOOGLE_API_KEY')
    cse_cx = os.getenv('GOOGLE_CSE_CX') or os.getenv('GOOGLE_CSE_ID') or os.getenv('GOOGLE_CSE_CX')

    if not cse_key or not cse_cx:
        print('è­¦å‘Šï¼šæœªæ‰¾åˆ° Custom Search API key æˆ– CXï¼Œagent åœ¨éœ€è¦æœå°‹æ™‚æœƒå¤±æ•—ã€‚')

    print('ğŸš€ Agent ready. è¼¸å…¥å•é¡Œï¼ˆè¼¸å…¥ exit æˆ– quit çµæŸï¼‰')
    while True:
        q = input('You: ')
        if q.strip().lower() in ['exit', 'quit']:
            print('Goodbye')
            break
        if not q.strip():
            continue

        decision = ask_llm_should_search(model, q)
        need_search = bool(decision.get('need_search', False))
        search_query = decision.get('query', '')

        if need_search and search_query and cse_key and cse_cx:
            print(f"ğŸ” Agent æ±ºå®šè¦æœå°‹ï¼š{search_query}")
            items = fetch_search_results(search_query, cse_key, cse_cx, num_results=5)
            if not items:
                print('âš ï¸ æœå°‹æ²’æœ‰å›å‚³çµæœæˆ–ç™¼ç”ŸéŒ¯èª¤ï¼Œç›´æ¥è«‹ LLM å›ç­”ï¼ˆä¸ä½¿ç”¨æœå°‹çµæœï¼‰')
                ans = ask_llm_summarize(model, q, [])
            else:
                ans = ask_llm_summarize(model, q, items)
        else:
            # ä¸éœ€è¦æœå°‹ -> ç›´æ¥è®“ LLM å›ç­”
            print('ğŸ’¬ Agent æ±ºå®šä¸éœ€æœå°‹ï¼Œç›´æ¥ç”± LLM å›ç­”...')
            ans = ask_llm_summarize(model, q, [])

        print('\n=== Agent Answer ===')
        print(ans)
        print('====================\n')


if __name__ == '__main__':
    run_agent()
